{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a assignment to deal with unhealthy conversations. The assignment description website is in\n",
    "https://ml.auc-computing.nl/assignment3.html. The repository I used for the assignment is https://github.com/conversationai/unhealthy-conversations. There are some files I will use in my model: train.csv, test.csv, val.csv. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier, RandomForestClassifier, VotingClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"corpus/\")\n",
    "train_data= pd.read_csv(data_dir / \"train.csv\")\n",
    "test_data = pd.read_csv(data_dir / \"test.csv\")\n",
    "val_data = pd.read_csv(data_dir / \"val.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I delete 'trusted judgements', 'unit id', 'comment' in the columns_use, and the target_column would be the 'healthy' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_use = ['antagonise','antagonise:confidence','condescending','condescending:confidence',\n",
    "              'dismissive','dismissive:confidence','generalisation','generalisation:confidence',\n",
    "              'generalisation_unfair', 'generalisation_unfair:confidence','hostile',\n",
    "               'hostile:confidence', 'sarcastic','sarcastic:confidence']\n",
    "target_column = ['healthy']\n",
    "\n",
    "X_train = train_data[columns_use]\n",
    "y_train = train_data[target_column]\n",
    "\n",
    "X_test = test_data[columns_use]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "X_val = val_data[columns_use]\n",
    "y_val = val_data[target_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function combining each sub-attributes with its confidence score, and apply the function to X_train, and X_test. The way to combine the attributes with confidence socre is find the confidence scoe when the attribute is true. Therefore, if the attribute is 1, the confidence score should be 1*score, and if the attribute is 0, the confidence score should be 1*(1-score). Combining the two calculation, the new column should be 1*score + (1-1)*(1-score) for true, and 0*score + (1-0)*(1-score). After giving a new data to the attributes, we drop the columns of attributes confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['antagonise', 'condescending', 'dismissive', 'generalisation', \n",
    "             'generalisation_unfair', 'hostile', 'sarcastic']\n",
    "confidence = ['antagonise:confidence','condescending:confidence', \n",
    "                         'dismissive:confidence', 'generalisation:confidence', \n",
    "                         'generalisation_unfair:confidence', 'hostile:confidence', \n",
    "                         'sarcastic:confidence']\n",
    "    \n",
    "def preprocess(X):\n",
    "    for i in range(len(attributes)):\n",
    "        X[attributes[i]] = X[attributes[i]] * X[confidence[i]] + (1- X[attributes[i]]) * (1-X[confidence[i]])\n",
    "        \n",
    "preprocess(X_train)\n",
    "X_train = X_train.drop(confidence, axis=1)\n",
    "\n",
    "preprocess(X_test)\n",
    "X_test = X_test.drop(confidence, axis=1)\n",
    "\n",
    "preprocess(X_val)\n",
    "X_val = X_val.drop(confidence, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a score function which includes accuracy_score, confusion_matrix, precision_score, recall_score, and f1_score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        print(\"Train Result:\\n===========================================\")\n",
    "        print(f\"accuracy score: {accuracy_score(y_train, pred):.4f}\\n\")\n",
    "        print(f\"Classification Report: \\n \\tPrecision: {precision_score(y_train, pred)}\\n\\tRecall Score: {recall_score(y_train, pred)}\\n\\tF1 score: {f1_score(y_train, pred)}\\n\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, clf.predict(X_train))}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(X_test)\n",
    "        print(\"Test Result:\\n===========================================\")        \n",
    "        print(f\"accuracy score: {accuracy_score(y_test, pred)}\\n\")\n",
    "        print(f\"Classification Report: \\n \\tPrecision: {precision_score(y_test, pred)}\\n\\tRecall Score: {recall_score(y_test, pred)}\\n\\tF1 score: {f1_score(y_test, pred)}\\n\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train some classifiers and aggregate them in voting classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to train some classifiers and do hyper-parameter tuning to them, and then add them into voting classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model = LogisticRegression(max_iter=1000000)\n",
    "log_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next model I will build is a **random forest**. A random forest is considered an ensemble model in itself, since it is a collection of decision trees combined to make a more accurate model. I will then do hyper-parameter tuning to find the optimal number of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "# create a dictionary of all values we want to test for n_estimators\n",
    "params_rf = {'n_estimators': [50, 100, 200]}\n",
    "\n",
    "# use gridsearch to test all values for n_estimators\n",
    "rf_gs = GridSearchCV(rf, params_rf, cv=5)\n",
    "\n",
    "rf_gs.fit(X_train, y_train)\n",
    "\n",
    "# save best model\n",
    "rf_best = rf_gs.best_estimator_\n",
    "\n",
    "# check best n_estimators value\n",
    "print(rf_gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model I will build is **SVM**. I will use Gridsearch to find the optimal hyper-parameter as well. I get the optimal C=10, gamma=1, and kernel='rbf'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.945, total=   3.6s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.946, total=   3.9s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    7.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.946, total=   3.6s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.940, total=   3.6s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.942, total=   3.9s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.941, total=   3.8s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.925, total=   4.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.925, total=   4.3s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.925, total=   4.2s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.945, total=   4.6s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.947, total=   4.5s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.947, total=   4.5s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.943, total=   3.5s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.945, total=   3.7s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.944, total=   4.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.942, total=   3.9s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.942, total=   3.9s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.942, total=   3.9s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.946, total=   9.2s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.947, total=  10.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.947, total=   9.7s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.944, total=   4.3s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.946, total=   4.4s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.946, total=   4.4s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.943, total=   3.8s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.945, total=   3.9s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.944, total=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "sv = SVC()\n",
    "\n",
    "# defining parameter range \n",
    "param_sv = {'C': [0.1, 1, 10],  \n",
    "              'gamma': [1, 0.1, 0.01], \n",
    "              'kernel': ['rbf']}  \n",
    "  \n",
    "#use gridsearch to test all values\n",
    "sv_gs = GridSearchCV(sv, param_sv, refit = True, verbose = 3) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "sv_gs.fit(X_train, y_train) \n",
    "\n",
    "# save best model\n",
    "sv_best = sv_gs.best_estimator_\n",
    "\n",
    "# check best c, gamma, and kernel\n",
    "print(sv_gs.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hard voting**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9428248587570621\n",
      "RandomForestClassifier 0.9459887005649718\n",
      "SVC 0.9459887005649718\n",
      "VotingClassifier 0.9459887005649718\n"
     ]
    }
   ],
   "source": [
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[(\"lr\", log_model), (\"rf\", rf_best), (\"svc\", sv_best)],\n",
    "    voting=\"hard\",\n",
    ")\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "for clf in (log_model, rf_best, sv_best, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "===========================================\n",
      "accuracy score: 0.9522\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9573106283029947\n",
      "\tRecall Score: 0.9926327325864588\n",
      "\tF1 score: 0.9746517606265319\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 1201  1454]\n",
      " [  242 32606]]\n",
      "\n",
      "Test Result:\n",
      "===========================================\n",
      "accuracy score: 0.9459887005649718\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9554665409990575\n",
      "\tRecall Score: 0.9878197320341048\n",
      "\tF1 score: 0.9713738172236195\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 131  189]\n",
      " [  50 4055]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(voting_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(voting_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Soft voting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9428248587570621\n",
      "RandomForestClassifier 0.9455367231638419\n",
      "SVC 0.9459887005649718\n",
      "VotingClassifier 0.9446327683615819\n"
     ]
    }
   ],
   "source": [
    "soft_svm_clf = SVC(probability=True, C=10, gamma=1, kernel='rbf')\n",
    "\n",
    "soft_voting_clf = VotingClassifier(\n",
    "    estimators=[(\"lr\", log_model), (\"rf\", rf_best), (\"svc\", soft_svm_clf)],\n",
    "    voting=\"soft\",\n",
    ")\n",
    "soft_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "for clf in (log_model, rf_best, sv_best, soft_voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "===========================================\n",
      "accuracy score: 0.9541\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9574723760954307\n",
      "\tRecall Score: 0.9945202143205065\n",
      "\tF1 score: 0.9756447205339944\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 1204  1451]\n",
      " [  180 32668]]\n",
      "\n",
      "Test Result:\n",
      "===========================================\n",
      "accuracy score: 0.9446327683615819\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9534774436090225\n",
      "\tRecall Score: 0.9885505481120584\n",
      "\tF1 score: 0.9706972850137543\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 122  198]\n",
      " [  47 4058]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(soft_voting_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(soft_voting_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging involves taking multiple samples from my training data with replacement and training a model for each sample. The final output is averaged across the predictions of sub-models. The model I will use is bagged decision trees, random forest, and extra trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "===========================================\n",
      "accuracy score: 0.9459\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9565127538970241\n",
      "\tRecall Score: 0.9863309790550414\n",
      "\tF1 score: 0.9711930455635491\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 1182  1473]\n",
      " [  449 32399]]\n",
      "\n",
      "Test Result:\n",
      "===========================================\n",
      "accuracy score: 0.9441807909604519\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.957977207977208\n",
      "\tRecall Score: 0.9829476248477467\n",
      "\tF1 score: 0.9703017915113622\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 143  177]\n",
      " [  70 4035]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(),\n",
    "    n_estimators=500,\n",
    "    max_samples=100,\n",
    "    bootstrap=True,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "bag_clf.fit(X_train, y_train)\n",
    "print_score(bag_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(bag_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Out-of-bag Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9442018984311185"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    n_estimators=500,\n",
    "    bootstrap=True,\n",
    "    oob_score=True,\n",
    "    random_state=40,\n",
    ")\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "===========================================\n",
      "accuracy score: 0.9943\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9940676170586277\n",
      "\tRecall Score: 0.9998477837311252\n",
      "\tF1 score: 0.996949322324586\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 2459   196]\n",
      " [    5 32843]]\n",
      "\n",
      "Test Result:\n",
      "===========================================\n",
      "accuracy score: 0.9450847457627118\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9591060389919163\n",
      "\tRecall Score: 0.9827040194884288\n",
      "\tF1 score: 0.9707616411984117\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 148  172]\n",
      " [  71 4034]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(bag_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(bag_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=16,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "===========================================\n",
      "accuracy score: 0.9476\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9557581997352552\n",
      "\tRecall Score: 0.989131758402338\n",
      "\tF1 score: 0.9721586403961522\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 1151  1504]\n",
      " [  357 32491]]\n",
      "\n",
      "Test Result:\n",
      "===========================================\n",
      "accuracy score: 0.9455367231638419\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9560906515580736\n",
      "\tRecall Score: 0.9866017052375152\n",
      "\tF1 score: 0.971106581944611\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 134  186]\n",
      " [  55 4050]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(rnd_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(rnd_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra Trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                     max_depth=None, max_features=7, max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "                     oob_score=False, random_state=42, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_clf = ExtraTreesClassifier(n_estimators=1000, max_features=7, random_state=42,n_jobs=-1)\n",
    "ext_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "===========================================\n",
      "accuracy score: 0.9943\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9951466618133284\n",
      "\tRecall Score: 0.9987518265952265\n",
      "\tF1 score: 0.9969459849578363\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 2495   160]\n",
      " [   41 32807]]\n",
      "\n",
      "Test Result:\n",
      "===========================================\n",
      "accuracy score: 0.9385310734463277\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9588221211395739\n",
      "\tRecall Score: 0.9756394640682094\n",
      "\tF1 score: 0.967157691378894\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 148  172]\n",
      " [ 100 4005]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(ext_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(ext_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Booting algorithm trains weak learners sequencially. I will use AdaBoost and Gradient Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AdaBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=1,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort=False,\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=0.5, n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=200,\n",
    "    algorithm=\"SAMME.R\",\n",
    "    learning_rate=0.5,\n",
    "    random_state=42,\n",
    ")\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "===========================================\n",
      "accuracy score: 0.9459\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9558437730287399\n",
      "\tRecall Score: 0.9871833901607404\n",
      "\tF1 score: 0.9712608389618558\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 1157  1498]\n",
      " [  421 32427]]\n",
      "\n",
      "Test Result:\n",
      "===========================================\n",
      "accuracy score: 0.9414689265536723\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9548249763481551\n",
      "\tRecall Score: 0.9834348355663824\n",
      "\tF1 score: 0.96891875675027\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 129  191]\n",
      " [  68 4037]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(ada_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(ada_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stochastic Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=2,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=42, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_clf = GradientBoostingClassifier(max_depth=2,n_estimators=100, random_state=42)\n",
    "grad_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "===========================================\n",
      "accuracy score: 0.9483\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9564065581491185\n",
      "\tRecall Score: 0.989162201656113\n",
      "\tF1 score: 0.9725086424926296\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 1174  1481]\n",
      " [  356 32492]]\n",
      "\n",
      "Test Result:\n",
      "===========================================\n",
      "accuracy score: 0.9450847457627118\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9552098066949553\n",
      "\tRecall Score: 0.987088915956151\n",
      "\tF1 score: 0.9708877440996766\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 130  190]\n",
      " [  53 4052]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(grad_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(grad_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summaray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I dicovered ensemble machine learning algorithms to improve the performance of classifying healthy comments. I learned about Voting Ensembles for averaging the predictions for any arbitrary models, Bagging Ensembles including Bagged Decision Trees, Random Forest and Extra Trees, and Boosting Ensembles including AdaBoost and Gradient Boosting. My best model is the Hard voting classifier including Logistic regression, Random Forest classifier, and SVM. The model can predict the test dataset with accuracy score: 0.9459, Precision: 0.9554, Recall Score: 0.9878, F1 score: 0.9713. I think the reason why the hard voting classifier performs best is that I found the optimal hyper-parameter in the random forest and SVM which increase performance for the voting classifier. I will use my best model on the validation set to see the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Result:\n",
      "===========================================\n",
      "accuracy score: 0.944206008583691\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9496958352831072\n",
      "\tRecall Score: 0.9921779516010756\n",
      "\tF1 score: 0.9704722056186491\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 121  215]\n",
      " [  32 4059]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = voting_clf.predict(X_val)\n",
    "print(\"Val Result:\\n===========================================\")        \n",
    "print(f\"accuracy score: {accuracy_score(y_val, pred)}\\n\")\n",
    "print(f\"Classification Report: \\n \\tPrecision: {precision_score(y_val, pred)}\\n\\tRecall Score: {recall_score(y_val, pred)}\\n\\tF1 score: {f1_score(y_val, pred)}\\n\")\n",
    "print(f\"Confusion Matrix: \\n {confusion_matrix(y_val, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
