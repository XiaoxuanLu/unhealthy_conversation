{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a assignment to deal with unhealthy conversations. The assignment description website is in\n",
    "https://ml.auc-computing.nl/assignment3.html. The repository I used for the assignment is https://github.com/conversationai/unhealthy-conversations. There are some files I will use in my model: train.csv, test.csv, val.csv. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier, RandomForestClassifier, VotingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost.sklearn import XGBClassifier \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"corpus/\")\n",
    "train_data= pd.read_csv(data_dir / \"train.csv\")\n",
    "test_data = pd.read_csv(data_dir / \"test.csv\")\n",
    "val_data = pd.read_csv(data_dir / \"val.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I delete 'trusted judgements', 'unit id', 'comment' in the columns_use, and the target_column would be the 'healthy' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_use = ['antagonise','antagonise:confidence','condescending','condescending:confidence',\n",
    "              'dismissive','dismissive:confidence','generalisation','generalisation:confidence',\n",
    "              'generalisation_unfair', 'generalisation_unfair:confidence','hostile',\n",
    "               'hostile:confidence', 'sarcastic','sarcastic:confidence']\n",
    "target_column = ['healthy']\n",
    "\n",
    "X_train = train_data[columns_use]\n",
    "y_train = train_data[target_column]\n",
    "\n",
    "X_test = test_data[columns_use]\n",
    "y_test = test_data[target_column]\n",
    "\n",
    "X_val = val_data[columns_use]\n",
    "y_val = val_data[target_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function combining each sub-attributes with its confidence score, and apply the function to X_train, and X_test. The way to combine the attributes with confidence socre is find the confidence scoe when the attribute is true. Therefore, if the attribute is 1, the confidence score should be 1*score, and if the attribute is 0, the confidence score should be 1*(1-score). Combining the two calculation, the new column should be 1*score + (1-1)*(1-score) for true, and 0*score + (1-0)*(1-score). After giving a new data to the attributes, we drop the columns of attributes confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['antagonise', 'condescending', 'dismissive', 'generalisation', \n",
    "             'generalisation_unfair', 'hostile', 'sarcastic']\n",
    "confidence = ['antagonise:confidence','condescending:confidence', \n",
    "                         'dismissive:confidence', 'generalisation:confidence', \n",
    "                         'generalisation_unfair:confidence', 'hostile:confidence', \n",
    "                         'sarcastic:confidence']\n",
    "    \n",
    "def preprocess(X):\n",
    "    for i in range(len(attributes)):\n",
    "        X[attributes[i]] = X[attributes[i]] * X[confidence[i]] + (1- X[attributes[i]]) * (1-X[confidence[i]])\n",
    "        \n",
    "preprocess(X_train)\n",
    "X_train = X_train.drop(confidence, axis=1)\n",
    "\n",
    "preprocess(X_test)\n",
    "X_test = X_test.drop(confidence, axis=1)\n",
    "\n",
    "preprocess(X_val)\n",
    "X_val = X_val.drop(confidence, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a score function which includes accuracy_score, confusion_matrix, precision_score, recall_score, and f1_score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        print(\"Train Result:\\n===========================================\")\n",
    "        print(f\"accuracy score: {accuracy_score(y_train, pred):.4f}\\n\")\n",
    "        print(f\"Classification Report: \\n \\tPrecision: {precision_score(y_train, pred)}\\n\\tRecall Score: {recall_score(y_train, pred)}\\n\\tF1 score: {f1_score(y_train, pred)}\\n\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, clf.predict(X_train))}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(X_test)\n",
    "        print(\"Test Result:\\n===========================================\")        \n",
    "        print(f\"accuracy score: {accuracy_score(y_test, pred)}\\n\")\n",
    "        print(f\"Classification Report: \\n \\tPrecision: {precision_score(y_test, pred)}\\n\\tRecall Score: {recall_score(y_test, pred)}\\n\\tF1 score: {f1_score(y_test, pred)}\\n\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train some classifiers and aggregate them in voting classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to train some classifiers and do hyper-parameter tuning to them, and then add them into voting classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model = LogisticRegression(max_iter=1000000)\n",
    "log_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next model I will build is a **random forest**. A random forest is considered an ensemble model in itself, since it is a collection of decision trees combined to make a more accurate model. I will then do hyper-parameter tuning to find the optimal number of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "# create a dictionary of all values we want to test for n_estimators\n",
    "params_rf = {'n_estimators': [50, 100, 200]}\n",
    "\n",
    "# use gridsearch to test all values for n_estimators\n",
    "rf_gs = GridSearchCV(rf, params_rf, cv=5)\n",
    "\n",
    "rf_gs.fit(X_train, y_train)\n",
    "\n",
    "# save best model\n",
    "rf_best = rf_gs.best_estimator_\n",
    "\n",
    "# check best n_estimators value\n",
    "print(rf_gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model I will build is **SVM**. I will use Gridsearch to find the optimal hyper-parameter as well. I get the optimal C=10, gamma=1, and kernel='rbf'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.945, total=   3.8s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.946, total=   3.7s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    7.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.946, total=   3.5s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.940, total=   3.5s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.942, total=   3.8s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.941, total=   3.7s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.925, total=   4.2s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.925, total=   4.2s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.925, total=   4.1s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.945, total=   4.6s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.947, total=   4.5s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.947, total=   4.4s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.943, total=   3.4s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.945, total=   3.8s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.944, total=   4.1s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.942, total=   3.8s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.942, total=   3.8s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.942, total=   3.8s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.946, total=   8.7s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.947, total=   9.1s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.947, total=   9.6s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.944, total=   4.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.946, total=   3.8s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.946, total=   4.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.943, total=   3.4s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.945, total=   3.6s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.944, total=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "sv = SVC()\n",
    "\n",
    "# defining parameter range \n",
    "param_sv = {'C': [0.1, 1, 10],  \n",
    "              'gamma': [1, 0.1, 0.01], \n",
    "              'kernel': ['rbf']}  \n",
    "  \n",
    "#use gridsearch to test all values\n",
    "sv_gs = GridSearchCV(sv, param_sv, refit = True, verbose = 3) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "sv_gs.fit(X_train, y_train) \n",
    "\n",
    "# save best model\n",
    "sv_best = sv_gs.best_estimator_\n",
    "\n",
    "# check best c, gamma, and kernel\n",
    "print(sv_gs.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hard voting**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9428248587570621\n",
      "RandomForestClassifier 0.9466666666666667\n",
      "SVC 0.9459887005649718\n",
      "VotingClassifier 0.9459887005649718\n"
     ]
    }
   ],
   "source": [
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[(\"lr\", log_model), (\"rf\", rf_best), (\"svc\", sv_best)],\n",
    "    voting=\"hard\",\n",
    ")\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "for clf in (log_model, rf_best, sv_best, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "===========================================\n",
      "accuracy score: 0.9522\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9573106283029947\n",
      "\tRecall Score: 0.9926327325864588\n",
      "\tF1 score: 0.9746517606265319\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 1201  1454]\n",
      " [  242 32606]]\n",
      "\n",
      "Test Result:\n",
      "===========================================\n",
      "accuracy score: 0.9459887005649718\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9552520018841263\n",
      "\tRecall Score: 0.9880633373934227\n",
      "\tF1 score: 0.9713806729732967\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 130  190]\n",
      " [  49 4056]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(voting_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(voting_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Soft voting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9428248587570621\n",
      "RandomForestClassifier 0.9464406779661017\n",
      "SVC 0.9459887005649718\n",
      "VotingClassifier 0.9441807909604519\n"
     ]
    }
   ],
   "source": [
    "soft_svm_clf = SVC(probability=True, C=10, gamma=1, kernel='rbf')\n",
    "\n",
    "soft_voting_clf = VotingClassifier(\n",
    "    estimators=[(\"lr\", log_model), (\"rf\", rf_best), (\"svc\", soft_svm_clf)],\n",
    "    voting=\"soft\",\n",
    ")\n",
    "soft_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "for clf in (log_model, rf_best, sv_best, soft_voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "===========================================\n",
      "accuracy score: 0.9541\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9575565716965646\n",
      "\tRecall Score: 0.9945202143205065\n",
      "\tF1 score: 0.9756884296039662\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 1207  1448]\n",
      " [  180 32668]]\n",
      "\n",
      "Test Result:\n",
      "===========================================\n",
      "accuracy score: 0.9441807909604519\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9530295913574448\n",
      "\tRecall Score: 0.9885505481120584\n",
      "\tF1 score: 0.9704651440870502\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 120  200]\n",
      " [  47 4058]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(soft_voting_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(soft_voting_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging involves taking multiple samples from my training data with replacement and training a model for each sample. The final output is averaged across the predictions of sub-models. The model I will use is bagged decision trees, random forest, and extra trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "===========================================\n",
      "accuracy score: 0.9455\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9546176470588236\n",
      "\tRecall Score: 0.9880966877739893\n",
      "\tF1 score: 0.9710686931546194\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 1112  1543]\n",
      " [  391 32457]]\n",
      "\n",
      "Test Result:\n",
      "===========================================\n",
      "accuracy score: 0.9453107344632768\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9560802833530107\n",
      "\tRecall Score: 0.9863580998781973\n",
      "\tF1 score: 0.9709832134292566\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 134  186]\n",
      " [  56 4049]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(),\n",
    "    n_estimators=500,\n",
    "    max_samples=100,\n",
    "    bootstrap=True,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "bag_clf.fit(X_train, y_train)\n",
    "print_score(bag_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(bag_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Out-of-bag Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9442018984311185"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    n_estimators=500,\n",
    "    bootstrap=True,\n",
    "    oob_score=True,\n",
    "    random_state=40,\n",
    ")\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "===========================================\n",
      "accuracy score: 0.9943\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9940676170586277\n",
      "\tRecall Score: 0.9998477837311252\n",
      "\tF1 score: 0.996949322324586\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 2459   196]\n",
      " [    5 32843]]\n",
      "\n",
      "Test Result:\n",
      "===========================================\n",
      "accuracy score: 0.9450847457627118\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9591060389919163\n",
      "\tRecall Score: 0.9827040194884288\n",
      "\tF1 score: 0.9707616411984117\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 148  172]\n",
      " [  71 4034]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(bag_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(bag_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=16,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=200, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "===========================================\n",
      "accuracy score: 0.9477\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9563284056776017\n",
      "\tRecall Score: 0.9886446663419386\n",
      "\tF1 score: 0.9722180642457264\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 1172  1483]\n",
      " [  373 32475]]\n",
      "\n",
      "Test Result:\n",
      "===========================================\n",
      "accuracy score: 0.9462146892655368\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9572002837550249\n",
      "\tRecall Score: 0.9861144945188794\n",
      "\tF1 score: 0.9714422846172306\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 139  181]\n",
      " [  57 4048]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(rnd_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(rnd_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra Trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                     max_depth=None, max_features=7, max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "                     oob_score=False, random_state=42, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_clf = ExtraTreesClassifier(n_estimators=1000, max_features=7, random_state=42,n_jobs=-1)\n",
    "ext_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "===========================================\n",
      "accuracy score: 0.9943\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9951466618133284\n",
      "\tRecall Score: 0.9987518265952265\n",
      "\tF1 score: 0.9969459849578363\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 2495   160]\n",
      " [   41 32807]]\n",
      "\n",
      "Test Result:\n",
      "===========================================\n",
      "accuracy score: 0.9385310734463277\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9588221211395739\n",
      "\tRecall Score: 0.9756394640682094\n",
      "\tF1 score: 0.967157691378894\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 148  172]\n",
      " [ 100 4005]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(ext_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(ext_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Voting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use hard voting to enseblme the three models in bagging. A Voting Classifier is a machine learning model that trains on an ensemble of numerous models and predicts an output based on their highest probability of chosen class as the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('bag',\n",
       "                              BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                                                      criterion='gini',\n",
       "                                                                                      max_depth=None,\n",
       "                                                                                      max_features=None,\n",
       "                                                                                      max_leaf_nodes=None,\n",
       "                                                                                      min_impurity_decrease=0.0,\n",
       "                                                                                      min_impurity_split=None,\n",
       "                                                                                      min_samples_leaf=1,\n",
       "                                                                                      min_samples_split=2,\n",
       "                                                                                      min_weight_fraction_leaf=0.0,\n",
       "                                                                                      presort=False,\n",
       "                                                                                      random_state=42,\n",
       "                                                                                      splitter='best'),\n",
       "                                                boots...\n",
       "                                                   class_weight=None,\n",
       "                                                   criterion='gini',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features=7,\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=1000, n_jobs=-1,\n",
       "                                                   oob_score=False,\n",
       "                                                   random_state=42, verbose=0,\n",
       "                                                   warm_start=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv_clf = VotingClassifier(\n",
    "    estimators=[(\"bag\", bag_clf), (\"rnd\", rnd_clf ), (\"ext\", ext_clf)],\n",
    "    voting=\"hard\",\n",
    ")\n",
    "\n",
    "bv_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "===========================================\n",
      "accuracy score: 0.9943\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9940676170586277\n",
      "\tRecall Score: 0.9998477837311252\n",
      "\tF1 score: 0.996949322324586\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 2459   196]\n",
      " [    5 32843]]\n",
      "\n",
      "Test Result:\n",
      "===========================================\n",
      "accuracy score: 0.9444067796610169\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9579871825302635\n",
      "\tRecall Score: 0.9831912302070646\n",
      "\tF1 score: 0.970425583072854\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 143  177]\n",
      " [  69 4036]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(bv_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(bv_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Booting algorithm trains weak learners sequencially. I will use AdaBoost, Gradient Boosting, and XGB Boosting to see if add additional models to the overall ensemble model sequentially will increase the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AdaBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=1,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort=False,\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=0.5, n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=200,\n",
    "    algorithm=\"SAMME.R\",\n",
    "    learning_rate=0.5,\n",
    "    random_state=42,\n",
    ")\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "===========================================\n",
      "accuracy score: 0.9459\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9558437730287399\n",
      "\tRecall Score: 0.9871833901607404\n",
      "\tF1 score: 0.9712608389618558\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 1157  1498]\n",
      " [  421 32427]]\n",
      "\n",
      "Test Result:\n",
      "===========================================\n",
      "accuracy score: 0.9414689265536723\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9548249763481551\n",
      "\tRecall Score: 0.9834348355663824\n",
      "\tF1 score: 0.96891875675027\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 129  191]\n",
      " [  68 4037]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(ada_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(ada_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stochastic Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=2,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=42, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_clf = GradientBoostingClassifier(max_depth=2,n_estimators=100, random_state=42)\n",
    "grad_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "===========================================\n",
      "accuracy score: 0.9483\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9564065581491185\n",
      "\tRecall Score: 0.989162201656113\n",
      "\tF1 score: 0.9725086424926296\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 1174  1481]\n",
      " [  356 32492]]\n",
      "\n",
      "Test Result:\n",
      "===========================================\n",
      "accuracy score: 0.9450847457627118\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9552098066949553\n",
      "\tRecall Score: 0.987088915956151\n",
      "\tF1 score: 0.9708877440996766\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 130  190]\n",
      " [  53 4052]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(grad_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(grad_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGB Boost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=2,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=42, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(max_depth=2,n_estimators=100, random_state=42)\n",
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "===========================================\n",
      "accuracy score: 0.9509\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9581933887219374\n",
      "\tRecall Score: 0.9901059425231369\n",
      "\tF1 score: 0.9738883066327294\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 1236  1419]\n",
      " [  325 32523]]\n",
      "\n",
      "Test Result:\n",
      "===========================================\n",
      "accuracy score: 0.9455367231638419\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9563060935285782\n",
      "\tRecall Score: 0.9863580998781973\n",
      "\tF1 score: 0.9710996522364791\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 135  185]\n",
      " [  56 4049]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(xgb_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(xgb_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Voting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the same hard voting to ensemble the three models above together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('ada',\n",
       "                              AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                                 base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                                                       criterion='gini',\n",
       "                                                                                       max_depth=1,\n",
       "                                                                                       max_features=None,\n",
       "                                                                                       max_leaf_nodes=None,\n",
       "                                                                                       min_impurity_decrease=0.0,\n",
       "                                                                                       min_impurity_split=None,\n",
       "                                                                                       min_samples_leaf=1,\n",
       "                                                                                       min_samples_split=2,\n",
       "                                                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                                                       presort=False,\n",
       "                                                                                       random_state=None,\n",
       "                                                                                       sp...\n",
       "                                            max_delta_step=0, max_depth=2,\n",
       "                                            min_child_weight=1, missing=nan,\n",
       "                                            monotone_constraints='()',\n",
       "                                            n_estimators=100, n_jobs=0,\n",
       "                                            num_parallel_tree=1,\n",
       "                                            objective='binary:logistic',\n",
       "                                            random_state=42, reg_alpha=0,\n",
       "                                            reg_lambda=1, scale_pos_weight=1,\n",
       "                                            subsample=1, tree_method='exact',\n",
       "                                            validate_parameters=1,\n",
       "                                            verbosity=None))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf = VotingClassifier(\n",
    "    estimators=[(\"ada\", ada_clf), (\"grad\", grad_clf), (\"xgb\", xgb_clf)],\n",
    "    voting=\"hard\",\n",
    ")\n",
    "\n",
    "eclf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "===========================================\n",
      "accuracy score: 0.9487\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9570725671017354\n",
      "\tRecall Score: 0.9889186556259133\n",
      "\tF1 score: 0.9727350312177155\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 1198  1457]\n",
      " [  364 32484]]\n",
      "\n",
      "Test Result:\n",
      "===========================================\n",
      "accuracy score: 0.9450847457627118\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9558545797922569\n",
      "\tRecall Score: 0.9863580998781973\n",
      "\tF1 score: 0.9708668025416617\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 133  187]\n",
      " [  56 4049]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(eclf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(eclf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall I get a accuracy score for all my models. Hard voting for Linear regression, Random forest, and SVM performs best. I would like to choose some of them and then do voting classifier again with SVM, Random Forest, bagging decision tree, and XGB boost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                        | Linera regression | SVM    | Hard voting | Soft voting | Bagging(decision tree) | Random Forest | Extra trees | Bag voting | Ada boost | Gradient boosting | XGB boost | Boost voting |\n",
    "|------------------------|-------------------|--------|-------------|-------------|------------------------|---------------|-------------|------------|-----------|-------------------|-----------|--------------|\n",
    "| accuracy score of test | 0.9428            | 0.9460 | 0.9460      | 0.9441      | 0.9453                 | 0.9462        | 0.9385      | 0.9444     | 0.9414    | 0.9450            | 0.9455    | 0.9451       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('svc',\n",
       "                              SVC(C=10, cache_size=200, class_weight=None,\n",
       "                                  coef0=0.0, decision_function_shape='ovr',\n",
       "                                  degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
       "                                  probability=False, random_state=None,\n",
       "                                  shrinking=True, tol=0.001, verbose=False)),\n",
       "                             ('rnd',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features='auto...\n",
       "                                            max_delta_step=0, max_depth=2,\n",
       "                                            min_child_weight=1, missing=nan,\n",
       "                                            monotone_constraints='()',\n",
       "                                            n_estimators=100, n_jobs=0,\n",
       "                                            num_parallel_tree=1,\n",
       "                                            objective='binary:logistic',\n",
       "                                            random_state=42, reg_alpha=0,\n",
       "                                            reg_lambda=1, scale_pos_weight=1,\n",
       "                                            subsample=1, tree_method='exact',\n",
       "                                            validate_parameters=1,\n",
       "                                            verbosity=None))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf_final = VotingClassifier(\n",
    "    estimators=[(\"svc\", sv_best), (\"rnd\", rnd_clf), (\"bag\", bag_clf), (\"xgb\", xgb_clf)],\n",
    "    voting=\"hard\",\n",
    ")\n",
    "\n",
    "eclf_final.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "===========================================\n",
      "accuracy score: 0.9529\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9599870164360117\n",
      "\tRecall Score: 0.9904103750608865\n",
      "\tF1 score: 0.9749614157064298\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 1299  1356]\n",
      " [  315 32533]]\n",
      "\n",
      "Test Result:\n",
      "===========================================\n",
      "accuracy score: 0.9484745762711865\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.959033862183282\n",
      "\tRecall Score: 0.9866017052375152\n",
      "\tF1 score: 0.9726224783861672\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 147  173]\n",
      " [  55 4050]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(eclf_final, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(eclf_final, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summaray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I dicovered ensemble machine learning algorithms to improve the performance of classifying healthy comments. I learned about Voting Ensembles for averaging the predictions for any arbitrary models, Bagging Ensembles including Bagged Decision Trees, Random Forest and Extra Trees, and Boosting Ensembles including AdaBoost, Gradient Boosting, and XGB boost. My best model is the Hard voting classifier including SVM, Random Forest, bagging decision tree, and XGB boost. The model can predict the test dataset with accuracy score: 0.9484, Precision: 0.9590, Recall Score: 0.9866, F1 score: 0.9726. I choose these models to enseble is that they can perform individually themselves and combine them give me a better predictions. I will use the model on the val file to see the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Result:\n",
      "===========================================\n",
      "accuracy score: 0.944206008583691\n",
      "\n",
      "Classification Report: \n",
      " \tPrecision: 0.9496958352831072\n",
      "\tRecall Score: 0.9921779516010756\n",
      "\tF1 score: 0.9704722056186491\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 121  215]\n",
      " [  32 4059]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = voting_clf.predict(X_val)\n",
    "print(\"Val Result:\\n===========================================\")        \n",
    "print(f\"accuracy score: {accuracy_score(y_val, pred)}\\n\")\n",
    "print(f\"Classification Report: \\n \\tPrecision: {precision_score(y_val, pred)}\\n\\tRecall Score: {recall_score(y_val, pred)}\\n\\tF1 score: {f1_score(y_val, pred)}\\n\")\n",
    "print(f\"Confusion Matrix: \\n {confusion_matrix(y_val, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
